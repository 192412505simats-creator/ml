def entropy(data):
    labels = [row[-1] for row in data]
    return -sum((labels.count(c)/len(labels)) * log2(labels.count(c)/len(labels))
                for c in set(labels))
def info_gain(data, col):
    total = entropy(data)
    vals = set(row[col] for row in data)
    return total - sum(
        (len([r for r in data if r[col]==v])/len(data)) *
        entropy([r for r in data if r[col]==v])
        for v in vals
    )

def build_tree(data):
    labels = [row[-1] for row in data]
    if len(set(labels)) == 1:
        return labels[0]

    best = max(range(len(data[0])-1), key=lambda c: info_gain(data, c))
    tree = {}
    for v in set(row[best] for row in data):
        subset = [r for r in data if r[best]==v]
        tree[v] = build_tree(subset)
    return tree

data = [
 ['Sunny','Hot','High','Weak','No'],
 ['Sunny','Hot','High','Strong','No'],
 ['Overcast','Hot','High','Weak','Yes'],
 ['Rain','Mild','High','Weak','Yes'],
 ['Rain','Cool','Normal','Weak','Yes']
]
print("Decision Tree:", build_tree(data))
